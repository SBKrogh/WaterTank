\section{Reformulation of the objective function}
\label{ObjFunc_reform}

The minimization problem formulated in \secref{control_problem} describes the optimization subject to the WT dynamics and constraints. In order to make this problem solvable, the objective function has to match the state-space dynamics, therefore it has to be reformulated. As it is shown in \eqref{eqcost}, the hydraulic power is expressed with the flow through the pumps, however the dynamics include the WT pressure as a state. 
\\
In \secref{SystemLin_control} it is explained in detail by \eqref{statespace_control_sys_state}, how the independent flows of the network can be  calculated with the system matrices. Using this equation and plugging this into the objective function, the flows through the pumps can be obtained. Recalling that all the flows can be obtained from the independent flow variables, the flow through the pumps can be given with a linear mapping such that: 

\begin{equation}
\bm{q_p}[k]  = \bm{G_{2}} \bm{B_{1}^T}  \bm{z}[k]
\label{mapping_mainP}
\end{equation}

\begin{minipage}[t]{0.20\textwidth}
Where\\
\hspace*{8mm} $\bm{G_{2}} \in \bm{\mathbb{R}}^{(2 \times e)} $ 
\end{minipage}
\begin{minipage}[t]{0.68\textwidth}
\vspace*{2mm}
is a matrix representing a linear mapping between the flow through the two main pumps and the independent flows in the system. The dimension $e$ is the number of edges without the WT while the number of rows is the number of main pumps. 
\end{minipage} 

The system dynamics are only valid for small-signal values of the chord flows, and therefore for the small-signal values of the pump flows. As a consequence of this, $\bm{q_p}[k]$ can be written up as a sum of the operating point and the deviation from it:  

\begin{equation}
\bm{q_p}[k]  = \bm{\bar{q_p}} + \bm{\hat{q_p}}[k] = \bm{\bar{q_p}} + \bm{G_{2}} \bm{B_{1}^T}  \bm{\hat{z}}[k]
\label{mapping_mainP_1}
\end{equation}

\begin{minipage}[t]{0.20\textwidth}
Where\\
\hspace*{8mm} $ \bm{\bar{q_p}} $ \\
\hspace*{8mm} $ \bm{\hat{q_p}}[k] $ 
\end{minipage}
\begin{minipage}[t]{0.68\textwidth}
\vspace*{2mm}
is the operating value of the flow through the main pumps, \\
is the small-signal value of the flows through the main pumps. 
\end{minipage}
\begin{minipage}[t]{0.10\textwidth}
\vspace*{1.8mm}
\textcolor{White}{te}$\unit{m^3/h}$\\
\textcolor{White}{te}$\unit{m^3/h}$
\end{minipage}


The operating value for the pump flows can be determined by the linearized model of the pumps with the available pressure measurements. This is described in detail in \appref{cha:linear_pump}. This means that $\bm{\bar{q_p}}$ is given, and considered as a constant. 
\\
Plugging the expression for the small-signal chord flows given in \eqref{statespace_control_sys_state} into \eqref{mapping_mainP_1} and then into the objective function, the following yields:

%\begin{align}
% \Upsilon(\cdot) &= \frac{1}{\eta} \sum_{i=0}^{H_p-1} \Big( \bm{u^T}[k+i|k] \cdot  \bm{q_{p}}[k+i|k]\Big)\cdot c_p[k+i|k] \label{eqcost} 
%\end{align}

 \begin{equation}
 \bm{\hat{q_{p}}}[k] =   \bm{G_{2}} \bm{B_{1}^T}(-\bm{M_c^{-1}}\bm{N_c} \cdot \bm{\hat{u}}[k] -\bm{M_c^{-1}}\bm{Q_c} \cdot \bm{\hat{d}}[k] -\bm{M_c^{-1}}\bm{B_{o}} \cdot \Delta \hat{p}_{wt}[k])   
 \label{mappingandstates}
\end{equation}

\begin{minipage}[t]{0.80\textwidth}
Where\\
\hspace*{8mm} $\bm{\Lambda_1} = -\bm{G_{2}} \bm{B_{1}^T}\bm{M_c^{-1}}\bm{N_c} \in \pmb{\mathbb{R}}^{(2 \times 2)}$ \\
\hspace*{8mm} $\bm{\Lambda_2} = -\bm{G_{2}} \bm{B_{1}^T}\bm{M_c^{-1}}\bm{Q_c} \in \pmb{\mathbb{R}}^{(2 \times 4)}$ \\
\hspace*{8mm} $\bm{\Lambda_3} = -\bm{G_{2}} \bm{B_{1}^T}\bm{M_c^{-1}}\bm{B_{o}} \in \pmb{\mathbb{R}}^{(2 \times 1)}$ 
\end{minipage}

Therefore the small-signal flow through the main pumps can be written as: 

 \begin{equation}
 \bm{\hat{q}_{p}}[k] =   \bm{\Lambda_1} \bm{\hat{u}}[k] + \bm{\Lambda_2} \bm{\hat{d}}[k] + \bm{\Lambda_3} \Delta \hat{p}_{wt}[k]
 \label{pumpflows_simplified}
\end{equation}

Hence the objective function:

\begin{equation}
\! \Upsilon(\cdot) \!=\! \frac{1}{\eta}\! \sum_{i=0}^{H_p-1}\! \Big[ \bm{u^T}[k+i|k] \cdot \Big(\bm{\bar{q}_p} +  \bm{\Lambda_1} \bm{\hat{u}}[k+i|k] + \bm{\Lambda_2} \bm{\hat{d}}[k+i|k] + \bm{\Lambda_3} \Delta \hat{p}_{wt}[k+i|k]\!\Big)\!\Big] \! \cdot c_p[k+i|k]
\label{eqcost_3} 
\end{equation}

As can be seen in \eqref{eqcost_3}, the objective function now includes both the full- and small-signal inputs, the small-signal disturbances and the small-signal pressure in the WT.

As it was shown before, the WT pressure is described as a state in the dynamics governing the water distribution system. Therefore the state-space model in \eqref{dyn} can be used to substitute this pressure in \eqref{eqcost_3}.

However, before substituting the dynamics into the objective function, it is important to point out that an initial measurement of the states has to be available. Also important that here only the deviation from the operating point is taken into account, therefore the operating value of the WT pressure measurements has to be subtracted. Due to the available measurements it is possible to obtain the initial WT pressure at $i = 0$. For $i = 1$, the iteration of the state equation gives:

%We want a way to describe the dynamics of the system during the prediction horizon. $\Delta \hat p_{wt}[0]$ is know from a measurement. 
%The discrete system dynamics is stated in \eqref{extended_system_matrices}.

\begin{equation}
	\Delta \hat p_{wt}[1] = A_d\Delta \hat p_{wt}[0] + \bm{B_d} \bm{\hat{u}}[0] + \bm{E_d} \bm{\hat{d}}[0]
\end{equation}

Now $\Delta \hat p_{wt}[2]$ is calculated in the same way, but with $\Delta \hat{p_{wt}}[1]$ substituted: 

\begin{equation}
	\Delta \hat p_{wt}[2] = A_d\big[A_d\Delta \hat p_{wt}[0] + \bm{B_d}  \bm{\hat{u}}[0] + \bm{E_d}  \bm{\hat{d}}[0]\big] + \bm{B_d} \bm{\hat{u}}[1] + \bm{E_d} \bm{\hat{d}}[1]\\ 
\end{equation}

As can be seen, moving further in time steps, the predicted states only depend on the past values of the input, disturbance and the initial state measurement. Writing up the matrix equation until the $i = H_p - 1$ time steps, thus until the end of the prediction horizon, the following state dynamic matrix equation yields:

\begin{align}\hspace{-0.8cm}
\underbrace{\begin{bmatrix}
\Delta \hat p_{wt}[k\!+\!i\!+\!1|k] \\ 
\Delta \hat p_{wt}[k\!+\!i\!+\!1|k]\\ 
\vdots \\ 
\Delta \hat p_{wt}[k+H_p]\\ 
\end{bmatrix}}_{\bm{\Delta \hat{p}}_{wt,Hp}}
\!=\!
&\underbrace{\begin{bmatrix}
A_d \\ 
A_d^2\\ 
\vdots \\ 
A_d^{H_p}\\ 
\end{bmatrix}}_{\bm{\Phi}}
\!\bm{\Delta \hat{p}}_{wt}[0]\!+\!\nonumber
\underbrace{\begin{bmatrix}
 \bm{B_d}         & \bm{0}                &\hdots & \bm{0}\\ 
 A_d\bm{B_d}      &  \bm{B_d}             &\hdots & \bm{0}\\ 
\vdots            &\vdots                 &\ddots  & \vdots\\ 
 A_d^{H_p}\bm{B_d}& A_d^{H_p-1}\bm{B_d}   &\hdots & \bm{B_d}
\end{bmatrix}}_{\bm{\Gamma}}
\underbrace{\begin{bmatrix}
 \bm{\hat{u}}[k+i|k] \\ 
 \bm{\hat{u}}[k+i|k]\\ 
\vdots \\ 
 \bm{\hat{u}}[k\!+\!H_p\!-\!1|k]\\ 
\end{bmatrix}}_{\bm{\hat{u}}_{Hp}} \\
\!\!&+\! 
\underbrace{\begin{bmatrix}
 \bm{E_d}& 0 & \hdots  & 0\\ 
 A_d\bm{E_d}&  \bm{E_d}& \hdots & 0\\ 
\vdots &\vdots  & \ddots  & \vdots\\ 
 A_d^{H_p}\bm{E_d}& A_d^{H_p-1}\bm{E_d}  & \hdots  & \bm{E_d}
\end{bmatrix}}_{\bm{\Psi}}
\underbrace{\begin{bmatrix}
 \bm{\hat{d}}[k+i|k] \\ 
 \bm{\hat{d}}[k+i|k]\\ 
\vdots \\ 
 \bm{\hat{d}}[k+H_p-1|k]\\ 
\end{bmatrix}}_{\bm{\hat{d}}_{Hp}} 
\end{align}

Which in short form, expressed with the newly introduced vectors and matrices can be written as: 

\begin{equation}
	\bm{\Delta \hat{p}}_{wt,H_p} = \bm{\Phi} \bm{\Delta \hat{p}}_{\bm{wt}}[0] + \bm{\Gamma} \bm{\hat{u}}_{\bm{Hp}} + \bm{\Psi} \bm{\hat{d}}_{\bm{Hp}}
	\label{extendedmatrix}
\end{equation}

\begin{minipage}[t]{0.15\textwidth}
Where\\
\hspace*{8mm} $\bm{\Delta \hat{p}}_{wt,H_p} $ \\\newline
\hspace*{8mm} $\bm{\Delta \hat{p}}_{\bm{wt}}[0] $ \\\newline
\hspace*{8mm} $\bm{\hat{u}_{\bm{Hp}}}$ \\\newline
\hspace*{8mm} $\bm{\hat{d}_{\bm{Hp}}}$ \\\newline
\hspace*{8mm} $\bm{\Phi}$ \\\newline
\hspace*{8mm} $\bm{\Gamma}$ \\\newline
and \hspace*{0.7mm} $\bm{\Psi} $ 
\end{minipage}
\begin{minipage}[t]{0.13\textwidth}
\vspace*{2mm}
$\in \pmb{\mathbb{R}}^{(H_p \times 1)}$ \\\newline
$\in \pmb{\mathbb{R}}^{(H_p \times 1)}$ \\\newline
$\in \pmb{\mathbb{R}}^{(H_p \times 1)}$ \\\newline
$\in \pmb{\mathbb{R}}^{(H_p \times 1)}$ \\\newline
$\in \pmb{\mathbb{R}}^{(H_p \times 1)}$ \\\newline
$\in \pmb{\mathbb{R}}^{(H_p \times H_p)}$ \\\newline
$\in \pmb{\mathbb{R}}^{(H_p \times H_p)}$ 
\end{minipage}
 \begin{minipage}[t]{0.70\textwidth}
 \vspace*{2mm}
 is the predicted state vector calculated for the whole prediction horizon, \\
 is the initial state vector describing the whole prediction horizon, \\
 is the predicted input vector consisting of all the predicted values from the current time step until $k = H_p-1$, \\
 is the disturbance vector consisting of all the future values from the current time step until $k = H_p-1$, \\
 is the state matrix along the prediction horizon, taking $A_d$ into account at each time step, \\
 is the input matrix along the prediction horizon, taking $A_d$ and $\bm{B_d}$ matrix into account at each time step, \\
 is the disturbance matrix along the prediction horizon, taking the $A_d$ and $\bm{E_d}$ matrix into account at each time step . \\ 
 \end{minipage}

It is shown therefore that the state, input and disturbance matrices, described above, may be calculated prior to solving the MPC optimization. \eqref{extendedmatrix} defines the future state trajectories for each time step and for the whole prediction horizon. Furthermore, it is noted here that these matrices now describe the variables for the whole prediction horizon, and therefore the signals are subscripted with $H_p$. 
\\
\newline
Until this point, it was shown how the system dynamics can be written up for the whole prediction horizon, with the extended matrices and signal vectors that represent the predicted values of inputs, states and disturbances. However, the cost function is formulated in such a way that from the current time step,$k$ , the future values are iterated from $i = 0$ to $i = H_p - 1$ when calculating the price of energy usage for the whole interval. In order to replace this iterative summation with vector and matrix products, all signals and matrices are written up for the complete prediction horizon. Therefore the elements of the input vector now represent input configurations at different time steps moving towards the end of the interval, such that:

\begin{equation}
\bm{u_{Hp}} =  
 \begin{bmatrix}
  \bm{u}[k+i|k]\\
  \vdots  \\
  \bm{u}[k+H_p-1|k)   
 \end{bmatrix}
 \in \pmb{\mathbb{R}}^{(H_p \times 1)}
\end{equation}

and the disturbance vector therefore formulated as:

\begin{equation}
\bm{d_{Hp}} =  
 \begin{bmatrix}
  \bm{d}[k+i|k]\\
  \vdots  \\
  \bm{d}[k+H_p-1|k]   
 \end{bmatrix}
 \in \pmb{\mathbb{R}}^{(H_p \times 1)}
\end{equation}

Thus at time step $k$, these signals consist of the future input and disturbance vectors until the end of the horizon, which is $H_p - 1$ since $i$ is iterated from zero. 
\\
\newline
The objective function formulated in \eqref{eqcost_3} consists of the product of the $\bm{\Lambda_{1,2,3}}$ matrices and the signals. In order to express it in vectorial form, the cost function is plugged into these $\bm{\Lambda_{1,2,3}}$ matrices such that:

\begin{equation}
\bm{\Lambda_{1,Hp}} =
 \begin{bmatrix}
 \bm{\Lambda_1} c_p[k+i|k] & \hdots & \bm{0} \\
 \vdots & \ddots & \vdots\\
 \bm{0} & \hdots & \bm{\Lambda_1} c_p[k+H_p-1|k] 
 \end{bmatrix}
 \in \pmb{\mathbb{R}}^{(H_p \times H_p)}
\end{equation} 


\begin{equation}
\bm{\Lambda_{2,Hp}} =
 \begin{bmatrix}
 \bm{\Lambda_2} c_p[k+i|k] & \hdots & \bm{0} \\
 \vdots & \ddots & \vdots\\
 \bm{0} & \hdots & \bm{\Lambda_2} c_p[k+H_p-1|k] 
 \end{bmatrix}
 \in \pmb{\mathbb{R}}^{(H_p \times H_p)}
\end{equation} 


\begin{equation}
\bm{\Lambda_{3,Hp}} =
 \begin{bmatrix}
 \bm{\Lambda_3} c_p[k+i|k] & \hdots & \bm{0} \\
 \vdots & \ddots & \vdots\\
 \bm{0} & \hdots & \bm{\Lambda_3} c_p[k+H_p-1|k] 
 \end{bmatrix}
 \in \pmb{\mathbb{R}}^{(H_p \times H_p)}
\end{equation} 

It is important to point out that the system dynamics are described by small-signals, however as it is mentioned in the problem formulation, the optimization for the cost has to be according to full-signals. Since the dynamics are plugged into the objective function, the following has to be considered: 

\begin{equation}
\bm{u_{H{p}}} = \bm{\bar{u}_{H{p}}} + \bm{\hat{u}_{H{p}}}
\label{u_pred}
\end{equation}\\
and\\
\begin{equation}
\bm{d_{H{p}}} = \bm{\bar{d}_{H{p}}} + \bm{\hat{d}_{H{p}}}
\end{equation}

which shows that the signals and has to be decomposed to their constant values in the operating point and the small- signal deviations. 
\\
\newline
Now, that all the matrices and signals are represented in vectorial form along with their predicted values, the objective function can be written up such that:

\begin{equation}
  \Upsilon(\cdot) = \frac{1}{\eta} {\bm{{u}}}_{\bm{{Hp}}}^{T}\bigg[ {\bm{\bar{q}}}_{\bm{p,Hp}} + {\bm{\Lambda}}_{\bm{1,Hp}} {\bm{\hat{u}}}_{\bm{Hp}} + {\bm{\Lambda}}_{\bm{2,Hp}} {\bm{\hat{d}}}_{\bm{Hp}} 
  + {\bm{\Lambda}}_{\bm{3,Hp}} \bm{\Delta \hat{P}_{wt,Hp}} \bigg]
 \label{obj_hp}
\end{equation}

And then the dynamics of the system can be plugged into \eqref{obj_hp}:

\begin{equation}
\begin{aligned}
 \Upsilon(\cdot) = \frac{1}{\eta} {\bm{{u}}}_{\bm{Hp}}^{T}\bigg[ {\bm{\bar{q}}}_{\bm{p,Hp}} + {\bm{\Lambda}}_{\bm{1,Hp}} {\bm{\hat{u}}}_{\bm{Hp}} + {\bm{\Lambda}}_{\bm{2,Hp}} {\bm{\hat{d}}}_{\bm{Hp}} 
   \\ + {\bm{\Lambda}}_{\bm{3,Hp}} \bigg( \bm{\Phi} \bm{\Delta \hat{P}_{\bm{wt,Hp}}}[0] + \bm{\Gamma} \bm{\hat{u}}_{\bm{Hp}} + \bm{\Psi}\bm{\hat{d}}_{\bm{Hp}} \bigg) \bigg]
\end{aligned}
\label{obj_hp_dyn}
\end{equation}

By expressing the terms in \eqref{obj_hp_dyn}, the following yields:

\begin{equation}
\begin{aligned} 
 \Upsilon(\cdot) = & \frac{1}{\eta} \bigg[ \underbrace{{\bm{{u}}}_{\bm{Hp}}^{T}{\bm{\bar{q}}}_{\bm{p,Hp}}}_{\RN{1}} + \underbrace{{\bm{{u}}}_{\bm{Hp}}^{T}{\bm{\Lambda}}_{\bm{1,Hp}} {\bm{\hat{u}}}_{\bm{Hp}}}_{\RN{2}} + \underbrace{{\bm{{u}}}_{\bm{Hp}}^{T}{\bm{\Lambda}}_{\bm{2,Hp}} {\bm{\hat{d}}}_{\bm{Hp}} 
 }_{\RN{3}} + \underbrace{{\bm{{u}}}_{\bm{Hp}}^{T}{\bm{\Lambda}}_{\bm{3,Hp}}\bm{\Phi} \bm{\Delta \hat{P}_{\bm{wt,Hp}}}[0]}_{\RN{4}}
 \\
 & + \underbrace{{\bm{{u}}}_{\bm{Hp}}^{T}{\bm{\Lambda}}_{\bm{3,Hp}}\bm{\Gamma} \bm{\hat{u}}_{\bm{Hp}}}_{\RN{5}} + \underbrace{{\bm{{u}}}_{\bm{Hp}}^{T}{\bm{\Lambda}}_{\bm{3,Hp}}\bm{\Psi}\bm{\hat{d}}_{\bm{Hp}}}_{\RN{6}} \bigg]
 \end{aligned}
\end{equation}

Now, replacing all the full-signal input vectors according to \eqref{u_pred} with their operating and deviation values, the products of the different terms result in the following: 
\begin{align}
\text{\RN{1})} \:\:\: &({\bm{\bar{u}}}_{\bm{Hp}} + {\bm{\hat{u}}}_{\bm{Hp}})^{T} \bm{\bar{q}}_{\bm{p,Hp}}  = {\bm{\bar{u}}}_{\bm{Hp}}^{T} \bm{\bar{q}}_{\bm{p,Hp}} + {\bm{\hat{u}}}_{\bm{Hp}}^{T} \bm{\bar{q}}_{\bm{p,Hp}}\\
%
\text{\RN{2})} \:\:\: &({\bm{\bar{u}}}_{\bm{Hp}} + {\bm{\hat{u}}}_{\bm{Hp}})^{T} {\bm{\Lambda}}_{\bm{1,Hp}}{\bm{\hat{u}}_{\bm{Hp}}}  = {\bm{\bar{u}}}_{\bm{Hp}}^{T} {\bm{\Lambda}}_{\bm{1,Hp}} {\bm{\hat{u}}_{\bm{Hp}}} + {\bm{\hat{u}}}_{\bm{Hp}}^{T} {\bm{\Lambda}}_{\bm{1,Hp}} {\bm{\hat{u}}_{\bm{Hp}}} \\
%
\text{\RN{3})} \:\:\: &({\bm{\bar{u}}}_{\bm{Hp}} + {\bm{\hat{u}}}_{\bm{Hp}})^{T} {\bm{\Lambda}}_{\bm{2,Hp}} {\bm{\hat{d}}}_{\bm{Hp}}  = {\bm{\bar{u}}}_{\bm{Hp}}^{T} {\bm{\Lambda}}_{\bm{2,Hp}} {\bm{\hat{d}}_{\bm{Hp}}} 
 + {\bm{\hat{u}}}_{\bm{Hp}}^{T} {\bm{\Lambda}}_{\bm{2,Hp}} {\bm{\hat{d}}_{\bm{Hp}}}  \\
%
\text{\RN{4})}  \:\:\:&({\bm{\bar{u}}}_{\bm{Hp}} + {\bm{\hat{u}}}_{\bm{Hp}})^{T} {\bm{\Lambda}}_{\bm{3,Hp}} \bm{\Phi} \bm{\Delta \hat{P}_{\bm{wt,Hp}}}[0]   =  {\bm{\bar{u}}}_{\bm{Hp}}^{T} {\bm{\Lambda}}_{\bm{3,Hp}} \bm{\Phi} \bm{\Delta \hat{P}_{\bm{wt,Hp}}}[0] \nonumber\\
%
&+ {\bm{\hat{u}}}_{\bm{Hp}}^{T} {\bm{\Lambda}}_{\bm{3,Hp}} \bm{\Phi} \bm{\Delta \hat{P}_{\bm{wt,Hp}}}[0]  \\
%
\text{\RN{5})} \:\:\:&({\bm{\bar{u}}}_{\bm{Hp}} + {\bm{\hat{u}}}_{\bm{Hp}})^{T} {\bm{\Lambda}}_{\bm{3,Hp}} \bm{\Gamma} \bm{\hat{u}}_{\bm{Hp}}   =  {\bm{\bar{u}}}_{\bm{Hp}}^{T} {\bm{\Lambda}}_{\bm{3,Hp}} {\bm{\Gamma}} \bm{\hat{u}}_{\bm{Hp}} + 
 {\bm{\hat{u}}}_{\bm{Hp}}^{T} {\bm{\Lambda}}_{\bm{3,Hp}} \bm{\Gamma} \bm{\hat{u}}_{\bm{Hp}} \\
%
\text{\RN{6})} \:\:\:&({\bm{\bar{u}}}_{\bm{Hp}} + {\bm{\hat{u}}}_{\bm{Hp}})^{T} {\bm{\Lambda}}_{\bm{3,Hp}} \bm{\Psi} \bm{\hat{d}}_{\bm{Hp}}   =  {\bm{\bar{u}}}_{\bm{Hp}}^{T} {\bm{\Lambda}}_{\bm{3,Hp}} {\bm{\Psi}} \bm{\hat{d}}_{\bm{Hp}} + 
 {\bm{\hat{u}}}_{\bm{Hp}}^{T} {\bm{\Lambda}}_{\bm{3,Hp}} \bm{\Psi} \bm{\hat{d}}_{\bm{Hp}} 
 \label{obj_12}
\end{align}

As can be seen, there is only one variable in the objective function, which is the small-signal value of the input vector. The operating values of the inputs are the operating pressures of the two main pumps. Both the small-signal and operating point values of the disturbances are present. However, these disturbances are the ODs of the end-user valves, therefore they describe some kind of characteristics of water usage. The operating point values are known and are constant in the whole sequence. The small signal values are the deviations from this constant OD and also known, since the full-signal value of the whole disturbance sequence is known.
\\
As it was shown, all matrices are constants and can be calculated beforehand the optimization. 
\\
After rearranging the terms, it is shown in \eqref{obj_12} that the objective function consists of quadratic and linear terms of the variable $\bm{\hat{u}_Hp}$. Furthermore there are constants due to the operating values of the disturbances and inputs. Hence the quadratic term results in:

\begin{equation}
  \begin{split}
   \bm{\hat{u}}_{Hp}^{T}(\bm{\Lambda}_{1,Hp} + \bm{\Lambda}_{3,Hp} \bm{\Gamma} ) \bm{\hat{u}}_{Hp}
  \end{split}
\end{equation}

The linear term is given by: 

\begin{equation}
  \begin{split}
    & \bm{\bar{u}}_{\bm{Hp}}^{T}(\bm{\Lambda}_{\bm{1,Hp}} + \bm{\Lambda}_{\bm{3,Hp}} \bm{\Gamma} ) \bm{\hat{u}}_{\bm{Hp}} + \bm{\hat{u}}_{\bm{Hp}}^{T}(\bm{\Lambda}_{\bm{2,Hp}} + \bm{\Lambda}_{\bm{3,Hp}} \bm{\Psi} ) \bm{\hat{d}}_{\bm{Hp}}
    \\
    & + \bm{\hat{u}}_{\bm{Hp}}^{T}\bm{\Lambda}_{\bm{3,Hp}} \bm{\Phi} \bm{\Delta \hat{P}_{\bm{wt,Hp}}}[0] + \bm{\hat{u}}_{\bm{Hp}}^{T} \bm{\bar{q}}_{\bm{p,Hp}}
  \end{split}
\end{equation}

And the constants are given by:

\begin{equation}
    \bm{\bar{u}}_{\bm{Hp}}^{T}\bm{\bar{q}}_{\bm{p,Hp}}  + \bm{\bar{u}}_{\bm{Hp}}^{T}\bm{\Lambda}_{\bm{2,Hp}}\bm{\hat{d}}_{\bm{Hp}} + \bm{\bar{u}}_{\bm{Hp}}^{T}\bm{\Lambda}_{\bm{3,Hp}}\bm{\Phi} \bm{\Delta \hat{P}_{\bm{wt,Hp}}}[0] + \bm{\bar{u}}_{\bm{Hp}}^{T}\bm{\Lambda}_{\bm{3,Hp}}\bm{\Psi}\bm{\hat{d}}_{\bm{Hp}}
\end{equation}

Therefore it is shown that this optimization simplifies to a quadratic problem that can be written up in such a form as follows:

\begin{equation}
  \Upsilon(\cdot) = \frac{1}{\eta}\Big( \frac{1}{2} \bm{\hat{u}}_{\bm{Hp}}^{T} \bm{R} \bm{\hat{u}}_{\bm{Hp}} + \bm{b} \bm{\hat{u}}_{\bm{Hp}} + \bm{c} \Big)
\end{equation}

\begin{minipage}[t]{0.28\textwidth}
Where\\
\hspace*{8mm} $\bm{R} \in \pmb{\mathbb{R}}^{(H_p \times H_p)} $ \\
\hspace*{8mm} $\bm{b} \in \pmb{\mathbb{R}}^{(H_p \times 1)} $ \\
\hspace*{8mm} $\bm{c} \in \pmb{\mathbb{R}}^{(H_p \times 1)} $
\end{minipage}

Therefore the $\bm{R}$ matrix in the quadratic problem can be given as:

\begin{equation}
  \bm{R} = 2\Big(\bm{\Lambda}_{\bm{1,Hp}} + \bm{\Lambda}_{\bm{3,Hp}} \bm{\Gamma}\Big) 
\end{equation}

and the vector $\bm{b}$ can be given as:

\begin{equation}
\!\! b = \bm{\bar{u}}_{\bm{Hp}}^{T}(\bm{\Lambda}_{\bm{1,Hp}} \!+ \!\bm{\Lambda}_{\bm{3,Hp}} \bm{\Gamma} )\! + \!\bm{\hat{d}}_{\bm{Hp}}^{T}(\bm{\Lambda}_{\bm{2,Hp}}\! + \!\bm{\Lambda}_{\bm{3,Hp}} \bm{\Psi} )^{T}
  + \bm{\Delta \hat{P}_{\bm{wt,Hp}}}^{T}[0] (\bm{\Lambda}_{\bm{3,Hp}} \bm{\Phi})^{T} + {\bm{\bar{q}}^{T}}_{\bm{p,Hp}}
\end{equation}