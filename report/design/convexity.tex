\section{Convexity}
\label{convexity}
In the following section convexity of the objective function is examined. 
Due to the reformulation of the objective function and constraints, the MPC optimization problem becomes the following: 

\begin{align}
\underset{\bm{\hat{u}_{Hp}}}{min} \:  \Upsilon(\bm{\hat{u}}_{\bm{Hp}}) &= \underset{\bm{\hat{u}_{Hp}}}{min} \:  \frac{1}{\eta}\bigg( \frac{1}{2} \bm{\hat{u}}_{\bm{Hp}}^{T} \bm{R} \bm{\hat{u}}_{\bm{Hp}} + \bm{b} \bm{\hat{u}}_{\bm{Hp}} + c \bigg)\\
\label{eq:obj_final1}
%
s.t. \:\:\:\:\:	&\begin{bmatrix}
		\bm{I} 	\\
		-\bm{I} 	\\
		\bm{L_{y}}	\\
		-\bm{L_{y}}	\\
		\bm{\Gamma}	\\
		-\bm{\Gamma}
	\end{bmatrix}
	\begin{matrix}
			\bm{\hat{u}_{Hp}}
	\end{matrix}
	\geq 
	\begin{bmatrix}
			\bm{\hat{u}_{1}}	\\
			\bm{\hat{u}_{2}}	\\
			\bm{\hat{y}_{1}}	\\
			\bm{\hat{y}_{2}}	\\
			\bm{\Delta \hat{p}_{wt,1}}	\\
			\bm{\Delta \hat{p}_{wt,2}}	
	\end{bmatrix}
\end{align}
\todo{source maybe}

\textbf{Objective function}

As shown, the objective function and the constraints are all written up according to the small-signal value of the control signal. The difficulty of solving this optimization problem simplifies however, if $\Upsilon$ is convex. This is due to the fact that if the objective function is convex then any local minima is also the global minimum. 
\\
The function, $\Upsilon$, defines a quadratic surface. If this surface is convex, then it can be visualized such that in \figref{convexfig}. If the objective function is non-convex, the surface has a form such that in \figref{nonconvexfig}. 

\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \input{report/tikz/convex.tex} 
    \caption{Quadratic convex surface.}
    \label{convexfig}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \input{report/tikz/non_convex.tex} 
    \caption{Quadratic non-convex surface.}
    \label{nonconvexfig}
  \end{minipage}
  \label{fig:nonlinearpumps}
\end{figure}
%The gradient of the objective function tells the direction in which the change has the greatest rate. In case of convexity, this gradient vector points in the direction of the global minimum, therefore using iterative methods it can be found easily.

 \figref{convexfig} and \figref{nonconvexfig} points out the differences between the two minimization problems. Solving the convex quadratic problem results in a global minima in all cases. There is only one point along the curve when the first derivative equals to zero and that is the global minimum value of the function. However, considering non-convexity the same cannot be said, as the shape of the non-convex surface implies. 
\todo{source}
 In order to ensure convexity, the objective function must have a positive semi-definite Hessian matrix. The Hessian is a square matrix of second order partial derivatives of a scalar-valued function or scalar field. Therefore to obtain an expression that fulfills this condition, the Hessian is derived for \eqref{eq:obj_final1}: 

\begin{align}
%
\Upsilon(\bm{\hat{u}}_{\bm{Hp}}) &= \frac{1}{\eta}\bigg( \frac{1}{2} \bm{\hat{u}}_{\bm{Hp}}^{T} \bm{R} \bm{\hat{u}}_{\bm{Hp}} + \bm{b} \bm{\hat{u}}_{\bm{Hp}} + c \bigg)\\
%
\frac{\partial \Upsilon(\bm{\hat{u}}_{\bm{Hp}})}{\partial \bm{\hat{u}}_{\bm{Hp}}} &= \frac{1}{\eta}\cdot \big(\bm{R} \bm{\hat{u}}_{\bm{Hp}} + \bm{b} \big)\\
%
\frac{\partial^2 \Upsilon(\bm{\hat{u}}_{\bm{Hp}})}{\partial \bm{\hat{u}}_{\bm{Hp}}} &= \frac{1}{\eta}\cdot \bm{R} 
\label{hessian}
%
\end{align}

\eqref{hessian} shows that convexity is ensured if:

\begin{equation}
\bm{R} \succeq 0  
\end{equation}

for all $\bm{\hat{u}}_{\bm{Hp}} $, since the efficiency, $\eta$ is a positive constant, therefore does not change the convexity of the function. 

$\bm{R}$ depends on $\bm{\Lambda_1}$ from \eqref{pumpflows_simplified}, which is defined as $\bm{\Lambda_1} = \bm{G_{2}} \bm{B_{1}^T}\bm{M_c^{-1}}\bm{N_c}$. Every term in this expression is known and positive semi-definite, except $\bm{M_c}$, which includes all the resistance terms as an outcome of the parameter estimation. Therefore $\bm{M_c}$ must be positive semi-definite. To ensure that the objective function is convex, this requirement has been explained in detail in the formulation of \eqref{statespace_control_sys_state}.  

% The definition of a convex function can be written as, $\triangledown(\triangledown g(\cdot)) \geq 0$,  and the definition of a strictly convex function as $\triangledown(\triangledown g(\cdot)) > 0$. For the purpose of this project is it only required for the optimization problem to be convex. 





%
%\begin{align}
%\underset{\bm{\hat{u}_{Hp}}}{min} \:  \Upsilon(\cdot) &= \underset{\bm{\hat{u}_{Hp}}}{min} \:  \frac{1}{\eta}\bigg( \frac{1}{2} \bm{\hat{u}}_{\bm{Hp}}^{T} \bm{R} \bm{\hat{u}}_{\bm{Hp}} + \bm{b} \bm{\hat{u}}_{\bm{Hp}} + c \bigg)\\
%
%\Upsilon(\cdot) &= \frac{1}{\eta}\bigg( \frac{1}{2} \bm{\hat{u}}_{\bm{Hp}}^{T} \bm{R} \bm{\hat{u}}_{\bm{Hp}} + \bm{b} \bm{\hat{u}}_{\bm{Hp}} + c \bigg)\\
%
%\triangledown \Upsilon(\cdot) &= \frac{1}{\eta}\cdot \big(\bm{R} \bm{\hat{u}}_{\bm{Hp}} + \bm{b} \big)\\
%
%\triangledown(\triangledown \Upsilon(\cdot)) &= \frac{1}{\eta}\cdot \bm{R} 
%
%\end{align}



\textbf{Constraints}

The convexity of the constraints is investigated with the same procedure as for the objective function. All constraints are linear and the Hessian of a linear function, $Ax+b$, is always zero. Therefore the constraints are always convex.

%In this section:
%\\
%-show how the quadratic problem can be solved
%-prove positive semi-definiteness
